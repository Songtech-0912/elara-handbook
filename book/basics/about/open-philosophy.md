# Open Philosophy

> "As we enjoy great advantages from the inventions of others, we should be glad of an opportunity to serve others by any invention of ours, and this we should do freely and generously."
>
> **Benjamin Franklin**

Project Elara's mission is one that cannot be accomplished without a philosophy of openness. After all, how would there be much benefit from our work if its knowledge is confined to only a few individuals, or only available for exorbitant sums? Rather, science should be open and should benefit everyone. For this reason, we release our work under the principles of **open science** and **open knowledge**:

- The project is a collaborative **open effort**, with contributions from all being accepted
- All code written as part of the project is **open-source** and **dedicated to the public domain**
- All creative resources of the project are licensed under the **CC0 public domain license**
- All hardware produced in the project will be **open hardware** with documentation and design specifications freely available

By dedicating Project Elara to the public domain, we have greater confidence that no one can take control of the technology for themselves, and everyone will be ensured free and unlimited access to the research. 

## An ethical research approach

It is an unfortunate that while the sciences are meant to be a quest to push the bounds of human understanding and knowledge, it easily becomes a chase for fame and recognition. We are _not_ the only team working on space-based solar and related high-precision beam focusing; among the many other teams include a [brilliant team from Caltech](https://arxiv.org/abs/2206.08373), the [LISA team](https://lisa.nasa.gov/meetTheTeam.html) working on fantastic laser interferometery, and researchers at the [OTPS at NASA](https://www.nasa.gov/directorates/stmd/space-based-solar-power-report/) (the list is most certainly non-exhaustive and too short to list the contributions of every team and scientist).

Another common side-effect of the ills of scientific competition is the omission of credit to those who made a discovery or an innovation possible. The individual egos of scientists (or nations funding the work of scientists) makes it tempting to downplay the work of others - especially of scientists who came from disadvantaged backgrounds - and make it seem like it was the work of a single individual or group. To us, this is **unacceptable**.

At Project Elara, we have **no interest** in competing with any other groups working on the same technology. To the highest extent we possibly can, we will freely extend offers of collaboration, freely share our research and technological breakthroughs (the Project is structured around this principle) and assist our colleagues in whichever way we can. When we use the work of others, this **must** be acknowledged as their work and not our own work. In doing so, we hope to build others up instead of tearing others down, because, to put down _even one scientist_ amounts to a gigantic loss to the field as well as a human trajedy.

In addition, we **never** want to start a priority dispute nor pass over the contributions of any scientist. Internally, we have a firm policy that **fair credit must be given to all who make contributions within the Project**. In our "Credits" section in the Appendix of the Handbook, we have a list that attempts to chronicle every contribution to the Project. This list is certainly imperfect - realistic constraints mean it will never be fully accurate nor exhaustive - but we hope that this builds trust in our team in that no contribution is forgotten.

## Our standards regarding AI-based tools

In our quest for scientific identity, we cannot afford to not consider the circumstances of this new era (at the time of writing) of the widespread use of AI-based tools, such as ChatGPT. These tools are powerful, and we do indeed use these tools in the course of our research. For instance, we frequently use ChatGPT to learn, discover new ideas, and investigate new approaches to solving problems. We may even ask for it to suggest ideas for how to solve a particular physical or engineering problem.

But crucially, there are several guidelines that we need to follow in doing so. First, _we must do our homework_. After learning something new from an AI-based tool, it is imperative that we **research it, learn about it,** and do our best to **understand it** and record down that knowledge in this Handbook for posterity. Simply taking ideas from ChatGPT as if it were our own work, or copy-and-pasting its responses verbatim, is **unacceptable**.

Second, _every_ idea that was **not novel**, whether it came from an AI-based tool or from another scientist's (or team's) paper or article must be traced back to its source and credited, as far as is realistically possible. After all, AI-generated tools rarely make something _new_ as much as piece together information that was fed to them during the training process. The ideas came from another scientist (or team of researchers). While it is not always possible to either automatically or manually find the sources used by an AI-based tool in one of its responses, we will do our best to try.

## Scientific integrity

While it is essential that science is performed in a manner that gives honest results - even if those results aren't necessarily groundbreaking - this is very often tossed aside out of personal greed. Faking results, attempting to inflate poor results, or data manipulation to support a certain claim are common violations of scientific integrity. The highly-competitive research environment, often characterized by the term _publish-or-perish_, exacerbates and encourages this (mis)behavior. We are aware that simply because we stand for high ideals **does not make us immune to this behavior**, and thus we must take steps to avoid it to the furthest extent possible.

First, just as we mentioned earlier, we want to work together with other scientists working on the same (or similar) things so that we are not trying to gain a "competitive edge", so to speak, over another group of scientists. We will extend out offers of collaboration in good faith and willingly encourage the participation of others. In this way, we can mitigate one of the big drivers of scientific dishonesty - the fear that someone will "get to it first".

Second, we will identify any flaws we can find in our research and continually test and re-test, fixing any issues we find and noting this process, before publishing. Yes, realistic considerations may force us to shorten this process, but we will always aim to perform an internal review process. We will also encourage **mentioning null results or unexpected results**. While others may regard it as embarassing, we believe that sharing such results allows others to not repeat a flawed process we used and to know the difficulties and the dead-ends of a particular research pathway.

At the end of the day, we are imperfect human beings who make mistakes. However, we belive that establishing these guidelines is our best hope of preventing the most egregious ethical violations and encouraging high scientific ethical standards and paving the way for a future based in collaboration and fellowship for humankind.